{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Speaker",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMGRs0O+rJPiLW+D3IuHKal",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/franciscojferrari/AUTOVC/blob/speaker-encoder/Speaker.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lirAhAKtesh8"
      },
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM,Dense,Lambda,Masking\n",
        "from tensorflow import keras\n",
        "import sys\n",
        "import keras.backend as K\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vDprq4LSycpj"
      },
      "source": [
        "def speaker_centroids(embeddings):\n",
        "    \"\"\"\n",
        "    Inputs:\n",
        "        embeddings: Embeddings from encoder, shape=(speakers_per_batch, utterances_per_speaker, embedding_size)\n",
        "\n",
        "    Returns\n",
        "        Speaker centroids of shape=(speakers_per_batch, 1, embedding_size).\n",
        "    \"\"\"\n",
        "    speaker_centroids = tf.math.reduce_mean(embeddings, axis=1, keepdims=True)\n",
        "    speaker_centroids = tf.identity(speaker_centroids) / (\n",
        "        tf.norm(speaker_centroids, axis=2, keepdims=True) + 1e-6\n",
        "    )\n",
        "\n",
        "    return speaker_centroids"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QjZ2hIh9X03r"
      },
      "source": [
        "\n",
        "def similarity_matrix(embeddings, speaker_centroids, utterance_centroids):\n",
        "    \"\"\"\n",
        "    Inputs:\n",
        "        embeddings: Embeddings from encoder, shape=(speakers_per_batch, utterances_per_speaker, embedding_size)\n",
        "        speaker_centroids: Speaker centroids of shape=(speakers_per_batch, 1, embedding_size).\n",
        "        utterance_centroids: Utterance centroids of shape=(speakers_per_batch, 1, embedding_size).\n",
        "\n",
        "    Returns\n",
        "        Similarity matrix of shape=(speakers_per_batch, utterances_per_speaker, speakers_per_batch).\n",
        "    \"\"\"\n",
        "    speakers_per_batch = embeddings.shape[0]\n",
        "    mask_matrix = 1 - tf.eye(speakers_per_batch)\n",
        "    sim_values = []\n",
        "\n",
        "    for j in range(speakers_per_batch):\n",
        "        mask = tf.transpose(tf.where(mask_matrix[j]))[0]\n",
        "        a = tf.reduce_sum(tf.gather(embeddings, mask) * speaker_centroids[j], axis=2)\n",
        "        b = tf.reshape(\n",
        "            tf.reduce_sum(embeddings[j] * utterance_centroids[j], axis=1), shape=(1, -1)\n",
        "        )\n",
        "\n",
        "        # Make sure that b is inserted in the right place.\n",
        "        a = tf.unstack(a, axis=0)\n",
        "        b = tf.unstack(b, axis=0)\n",
        "        a.insert(j, b[0])\n",
        "        c = tf.stack(a, axis=-1)\n",
        "\n",
        "        sim_values.append(c)\n",
        "\n",
        "    sim_values = [\n",
        "        tf.expand_dims(tf.transpose(m), axis=-1) for m in sim_values\n",
        "    ]  # Add additional dimension\n",
        "    sim_matrix = tf.concat(sim_values, axis=2)\n",
        "\n",
        "    return sim_matrix\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNmgo3IXX5qj"
      },
      "source": [
        "def utterance_centroids(embeddings):\n",
        "    \"\"\"\n",
        "    Inputs:\n",
        "        embeddings: Embeddings from encoder, shape=(speakers_per_batch, utterances_per_speaker, embedding_size)\n",
        "\n",
        "    Returns\n",
        "        Utterance centroids of shape=(speakers_per_batch, 1, embedding_size).\n",
        "    \"\"\"\n",
        "    utterances_per_speaker = embeddings.shape[1]\n",
        "\n",
        "    utterance_centroids = (\n",
        "        tf.math.reduce_sum(embeddings, axis=1, keepdims=True) - embeddings\n",
        "    )\n",
        "    utterance_centroids /= utterances_per_speaker - 1\n",
        "    utterance_centroids = tf.identity(utterance_centroids) / (\n",
        "        tf.norm(utterance_centroids, axis=2, keepdims=True) + 1e-6\n",
        "    )\n",
        "\n",
        "    return utterance_centroids"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WY50pokha6lN"
      },
      "source": [
        "def calculate_loss(sim_matrix):\n",
        "  same_idx = list(range(sim_matrix.shape[0]))\n",
        "  sim_matrix = sim_matrix.numpy()\n",
        "  pos = sim_matrix[same_idx, :, same_idx]\n",
        "  in_neg = (np.exp(sim_matrix))\n",
        "  neg = np.log(np.sum(in_neg,axis=2)+ 1e-6)\n",
        "  per_embedding_loss = -1 * (pos - neg)\n",
        "  loss = per_embedding_loss.sum()\n",
        "  return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HzdI5UswfKLT"
      },
      "source": [
        "class SpeechEmbedder(keras.layers.Layer):\n",
        "    def __init__(self, time_dim=13, melfilters_dim=32):\n",
        "        super(SpeechEmbedder, self).__init__()\n",
        "        self.model = Sequential()\n",
        "        self.model.add(Masking(mask_value=-1.0,\n",
        "                                  input_shape=(time_dim, melfilters_dim)))\n",
        "        \n",
        "        self.model.add(LSTM(768, return_sequences=True,\n",
        "                            input_shape= (None,melfilters_dim)))\n",
        "        self.model.add(LSTM(768))\n",
        "        #TODO: check activation function\n",
        "        self.model.add(Dense(256,activation='relu'))\n",
        "        #TODO: check if this L2 normalization is well done\n",
        "        self.model.add(Lambda(lambda x: K.l2_normalize(x,axis=1)))\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return self.model.predict(inputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2mS0maBknvOa"
      },
      "source": [
        "class GE2ELoss(keras.layers.Layer):\n",
        "    def __init__(self):\n",
        "        super(GE2ELoss, self).__init__()\n",
        "        self.w = tf.Variable(initial_value=10.0, trainable=True)\n",
        "        self.b = tf.Variable(initial_value=-5.0, trainable=True)\n",
        "        \n",
        "    def call(self, inputs):\n",
        "        #constrain w > 0, to have larger similarity when cosine similarity is larger. \n",
        "        tf.clip_by_value(self.w, clip_value_min=1e-6, clip_value_max=np.inf)\n",
        "        centroids = speaker_centroids(inputs)\n",
        "        ut_centroids = utterance_centroids(inputs)\n",
        "        coss_sim = similarity_matrix(inputs,centroids,ut_centroids)\n",
        "        sim_matrix = self.w*coss_sim + self.b\n",
        "        loss = calculate_loss(sim_matrix)\n",
        "        return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AbYl_LOHnNmw"
      },
      "source": [
        "Experiment Speech Embedder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZayivCFjfMUU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9faa2a2-d0cd-431d-ed9a-dd318a8a356b"
      },
      "source": [
        "#Speech Embedder experiment\n",
        "number_of_speakers = 12\n",
        "utterances_per_speaker = 10\n",
        "data_points = number_of_speakers *utterances_per_speaker #Number of utterances\n",
        "dimension = 13 #Number of time steps\n",
        "time_steps = 3 #Feature dimension\n",
        "data = np.random.rand(data_points,time_steps,dimension)\n",
        "data.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(120, 3, 13)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x0HhgkmqfODm",
        "outputId": "04c3cf77-7a8d-41bd-8bc1-b63e7b6fcf3a"
      },
      "source": [
        "model = SpeechEmbedder(time_steps, dimension)\n",
        "prediction = model.call(data)\n",
        "prediction.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(120, 256)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mMlBc5w00HWl"
      },
      "source": [
        "We need to reshape the data to have it as (number of speakers, number of utterances per speaker, embedding)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TM-NU7QH0Igb",
        "outputId": "3927b0c6-d4c2-49ee-dec2-203f3b4df686"
      },
      "source": [
        "prediction = prediction.reshape((number_of_speakers,utterances_per_speaker,256))\n",
        "prediction.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(12, 10, 256)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y9HoiFhkxLdz"
      },
      "source": [
        "Testing speakers centroids"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TSvM7WoBfPpf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b243d640-668f-4050-98b1-8935653eef6e"
      },
      "source": [
        "centroids = speaker_centroids(prediction)\n",
        "centroids.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([12, 1, 256])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7FAi0HPKXDec"
      },
      "source": [
        "Testing utterance centroids"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dvoTmuPcxSxp",
        "outputId": "01fe3246-5f6d-4d02-b7a5-9792e3ed13de"
      },
      "source": [
        "#TODO: check that this is well done.. the shape not really\n",
        "ut_centroids = utterance_centroids(prediction)\n",
        "ut_centroids.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([12, 10, 256])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yyVbmbzo4bWr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be1e64c7-e6ce-46b0-e43b-96d226c13e4a"
      },
      "source": [
        "coss_sim = similarity_matrix(prediction,centroids,ut_centroids)\n",
        "coss_sim.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([12, 10, 12])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4SmcH7n0ZmpB"
      },
      "source": [
        "Testing with class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Am1ET2nnY8Kz",
        "outputId": "dcb417d4-68d9-4274-8042-f31f1232225c"
      },
      "source": [
        "loss_model = GE2ELoss()\n",
        "loss = loss_model.call(prediction)\n",
        "loss"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "300.5792"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3F46i3HHE0c0"
      },
      "source": [
        "## Mounting bucket"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GcHnFFtcE0RV"
      },
      "source": [
        "from google.colab import auth"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yaFoNsB_E7Nw"
      },
      "source": [
        "auth.authenticate_user()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "waL8ODgpE9p7",
        "outputId": "6ebcd278-23c0-44f4-bd52-5ce1d434c346"
      },
      "source": [
        "!echo \"deb http://packages.cloud.google.com/apt gcsfuse-bionic main\" > /etc/apt/sources.list.d/gcsfuse.list\n",
        "!curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -\n",
        "!apt -qq update\n",
        "!apt -qq install gcsfuse"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100  2537  100  2537    0     0  70472      0 --:--:-- --:--:-- --:--:-- 72485\n",
            "OK\n",
            "40 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "gcsfuse is already the newest version (0.35.0).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 40 not upgraded.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_wY-dJo_FIwA",
        "outputId": "2caefc0d-c160-43c6-c18a-2a6769e9303c"
      },
      "source": [
        "!mkdir DataSet\n",
        "!gcsfuse autovc_datasets DataSet"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘DataSet’: File exists\n",
            "2021/04/27 14:06:27.525036 Using mount point: /content/DataSet\n",
            "2021/04/27 14:06:27.551423 Opening GCS connection...\n",
            "2021/04/27 14:06:28.477666 Mounting file system \"autovc_datasets\"...\n",
            "2021/04/27 14:06:28.519213 File system has been successfully mounted.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pSUPp8GGF7f5"
      },
      "source": [
        "## Read data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RDDOzUuuGTEN"
      },
      "source": [
        "! pip install -q tensorflow-io"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XP-r0zmQFUx8"
      },
      "source": [
        "import DataProcessing as dp\n",
        "import yaml\n",
        "import importlib\n",
        "from pathlib import Path\n",
        "import utils as utils\n",
        "\n",
        "from utils import parse_spectrograms\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import random"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14u6K7iWZNV7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0VBHddNeIUt4",
        "outputId": "2e4d874f-0bac-464b-eb0d-99f3684f7d2b"
      },
      "source": [
        "importlib.reload(dp)\n",
        "importlib.reload(utils)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<module 'utils' from '/content/utils.py'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "bJE5bq06Ghrd",
        "outputId": "a6f50902-6018-4485-b553-a9e3f853da9e"
      },
      "source": [
        "config = yaml.load(Path(\"config.yml\").read_text(), Loader=yaml.SafeLoader)\n",
        "data_reader = dp.DataReader(config)\n",
        "data_reader.find_data_sets()\n",
        "data_reader.load_datasets()\n",
        "test_data = data_reader.datasets[\"103\"]\n",
        "for i in test_data.take(2):\n",
        "  example = parse_spectrograms(i)\n",
        "  \n",
        "plt.figure(figsize=(15,4))\n",
        "spect = tf.math.log(example[\"mel_spectrogram\"]).numpy()\n",
        "spect.shape\n",
        "#plt.imshow(spect, aspect=\"auto\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'dataset': {'train-clean-100': 'librispeech/downloads/extracted/TAR_GZ.openslr.org_resource_12_train-clean-1001N3R1aarMDBm8Ulx12juQyeKXyoKpD3HFrDmTsu79uI.tar.gz/LibriSpeech/train-clean-100', 'train-clean-360': 'librispeech/downloads/extracted/TAR_GZ.openslr.org_resource_12_train-clean-360FGpWSWIX6WwUM0oWDfl__-3W4KBOZrnFrw1Avjx5Ls8.tar.gz.incomplete_419af91646134b46a332a6d1f38e0261/LibriSpeech/train-clean-360', 'train-clean-500': 'librispeech/downloads/extracted/TAR_GZ.openslr.org_resource_12_train-other-5003bIvJ_luwWNkXVMhVVnfaqNlFfJuAd1weYGINQrcttI.tar.gz.incomplete_4fa7adaee06441e9b95cf97e93617ee2/LibriSpeech/train-other-500', 'dev-clean': 'librispeech/downloads/extracted/TAR_GZ.openslr.org_resources_12_dev-cleandvh9CQZQYX_KDKyPiLlBbg6_gDUKy5ezQ6hfqQNyirM.tar.gz/LibriSpeech/dev-clean', 'test-clean': 'librispeech/downloads/extracted/TAR_GZ.openslr.org_resources_12_test-cleanOf3lJeWWctxtFVGRmxR49yRDipWqVfh0tXa-IZZ-bCM.tar.gz/LibriSpeech/test-clean', 'vctk': 'vctk/mic1/1.0.0'}, 'write_path': 'processed_datasets', 'base_read_path': 'processed_datasets', 'bucket_name': 'DataSet', 'dataset_tf': 'librispeech', 'subdataset': 'train-clean-100', 'nfft': 512, 'window': 512, 'stride': 256, 'rate': 16000, 'mels': 128, 'fmin': 0, 'fmax': 8000}\n",
            "DataSet/processed_datasets/librispeech\n",
            "DataSet/processed_datasets/librispeech\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(872, 128)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1080x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o7PfNfoTORRE",
        "outputId": "0d6f3882-ccee-418c-9cab-42cbac559366"
      },
      "source": [
        "i[\"subset\"].numpy()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "b'\\x08\\x07\\x12\\x00B\\x05train'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2f5lueP4PWYR"
      },
      "source": [
        "def parse_spectrograms(example):\n",
        "    \"\"\"Convert the serialized tensor back to a tensor.\"\"\"\n",
        "    example = tf.io.parse_tensor(\n",
        "        example.numpy()[0], out_type=tf.float32\n",
        "    )\n",
        "    return example\n",
        "\n",
        "def create_batches(datasets, number_speakers, number_utterances):\n",
        "  list_speakers = random.sample(datasets.keys(),number_speakers)\n",
        "  batch = []\n",
        "  for speaker in list_speakers:\n",
        "      print(speaker)\n",
        "      list_utterances = datasets[speaker].shuffle(buffer_size=100).batch(number_utterances)\n",
        "      batch_speaker = next(iter(list_utterances))\n",
        "      for i in batch_speaker[\"mel_spectrogram\"]:\n",
        "        spectrogram = parse_spectrograms(i)\n",
        "        batch.append(spectrogram)\n",
        "  batch = tf.ragged.stack(batch, axis=0)     \n",
        "  return batch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a-ydqwmNPoBm",
        "outputId": "b0086270-bf80-489b-8669-fd5316da9f17"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1069\n",
            "5105\n",
            "6295\n",
            "260\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6olx6jFsSQ3G",
        "outputId": "4a9c6fcc-bb24-4e52-f843-9efdeeeb9bcf"
      },
      "source": [
        "batch.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([12, None, None])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kkXloisop1r_"
      },
      "source": [
        "# Testing with real data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K2T9P5CGleD2",
        "outputId": "6669333f-36a2-42f7-8ced-a6581fb9b3bf"
      },
      "source": [
        "\n",
        "number_of_speakers = 4\n",
        "utterances_per_speaker = 3\n",
        "\n",
        "batch = create_batches(data_reader.datasets,number_of_speakers,utterances_per_speaker)\n",
        "padded_inputs = tf.keras.preprocessing.sequence.pad_sequences(batch.numpy(), padding=\"post\", dtype='float32',value=-1.0)\n",
        "\n",
        "\n",
        "data_points = padded_inputs.shape[0]\n",
        "dimension = padded_inputs.shape[2]\n",
        "time_steps = padded_inputs.shape[1]   #Number of time steps\n",
        "\n",
        "model = SpeechEmbedder(time_steps, dimension)\n",
        "prediction = model.call(padded_inputs)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "251\n",
            "2035\n",
            "6313\n",
            "1272\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/ragged/ragged_tensor.py:2012: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return np.array(rows)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(12, 256)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7IVZI23utke_",
        "outputId": "875af877-2dd0-4f76-815b-fe32041476e9"
      },
      "source": [
        "prediction = prediction.reshape((number_of_speakers,utterances_per_speaker,256))\n",
        "prediction.shape\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4, 3, 256)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RprQo38xwoTc"
      },
      "source": [
        "loss_model = GE2ELoss()\n",
        "loss = loss_model.call(prediction)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bj757xbvw-hD",
        "outputId": "c5a7e146-708b-4108-8ec0-84ad2fb3cb33"
      },
      "source": [
        "loss"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "19.466358"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NWEwyEGwzON-"
      },
      "source": [
        "# Training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtQKUGLBzVmX"
      },
      "source": [
        "def grad(model,embedding):\n",
        "  with tf.GradientTape() as tape:\n",
        "    loss_model = GE2ELoss()\n",
        "    loss_value = loss_model.call(embedding)\n",
        "  return loss_value, tape.gradient(loss_value, model.trainable_variables)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "el-8GmQL2hNb"
      },
      "source": [
        "epochs = 200\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-5)\n",
        "for i in range(epochs):\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-ZVa6Kl150S"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}